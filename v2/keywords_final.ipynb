{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59826e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import boto3\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import torch\n",
    "pd.set_option('max_colwidth', None)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c23ec0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df02ebf-901b-43e9-8719-3ea17e4bfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_keep_ind(groups):\n",
    "    \"\"\"\n",
    "    Function to determine if a text should be kept or not.\n",
    "\n",
    "    Input:\n",
    "    groups: list of character groups\n",
    "\n",
    "    Output:\n",
    "    0: if text should be not used\n",
    "    1: if text should be used\n",
    "    \"\"\"\n",
    "    # Groups of characters that do not perform well\n",
    "    groups_to_skip = ['HIRAGANA', 'CJK', 'KATAKANA','ARABIC', 'HANGUL', 'THAI','DEVANAGARI','BENGALI',\n",
    "                      'THAANA','GUJARATI','CYRILLIC']\n",
    "    \n",
    "    if any(x in groups_to_skip for x in groups):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def remove_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to remove non-latin characters.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    final_char: string of characters with non-latin characters removed\n",
    "    \"\"\"\n",
    "    final_char = []\n",
    "    groups_to_skip = ['HIRAGANA', 'CJK', 'KATAKANA','ARABIC', 'HANGUL', 'THAI','DEVANAGARI','BENGALI',\n",
    "                      'THAANA','GUJARATI','CYRILLIC']\n",
    "    for char in text:\n",
    "        try:\n",
    "            script = unicodedata.name(char).split(\" \")[0]\n",
    "            if script not in groups_to_skip:\n",
    "                final_char.append(char)\n",
    "        except:\n",
    "            pass\n",
    "    return \"\".join(final_char)\n",
    "    \n",
    "def group_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to group non-latin characters and return the number of latin characters.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    groups: list of character groups\n",
    "    latin_chars: number of latin characters\n",
    "    \"\"\"\n",
    "    groups = []\n",
    "    latin_chars = []\n",
    "    text = text.replace(\".\", \"\").replace(\" \", \"\")\n",
    "    for char in text:\n",
    "        try:\n",
    "            script = unicodedata.name(char).split(\" \")[0]\n",
    "            if script == 'LATIN':\n",
    "                latin_chars.append(script)\n",
    "            else:\n",
    "                if script not in groups:\n",
    "                    groups.append(script)\n",
    "        except:\n",
    "            if \"UNK\" not in groups:\n",
    "                groups.append(\"UNK\")\n",
    "    return groups, len(latin_chars)\n",
    "\n",
    "def check_for_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to check if non-latin characters are dominant in a text.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    0: if text should be not used\n",
    "    1: if text should be used\n",
    "    \"\"\"\n",
    "    groups, latin_chars = group_non_latin_characters(str(text))\n",
    "    if name_to_keep_ind(groups) == 1:\n",
    "        return 1\n",
    "    elif latin_chars > 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55c7f0c-c028-48f0-8691-739f152a2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(old_title):\n",
    "    \"\"\"\n",
    "    Function to check if title should be kept and then remove non-latin characters. Also\n",
    "    removes some HTML tags from the title.\n",
    "    \n",
    "    Input:\n",
    "    old_title: string of title\n",
    "    \n",
    "    Output:\n",
    "    new_title: string of title with non-latin characters and HTML tags removed\n",
    "    \"\"\"\n",
    "    keep_title = check_for_non_latin_characters(old_title)\n",
    "    if (keep_title == 1) & isinstance(old_title, str):\n",
    "        new_title = remove_non_latin_characters(old_title)\n",
    "        if '<' in new_title:\n",
    "            new_title = new_title.replace(\"<i>\", \"\").replace(\"</i>\",\"\")\\\n",
    "                                 .replace(\"<sub>\", \"\").replace(\"</sub>\",\"\") \\\n",
    "                                 .replace(\"<sup>\", \"\").replace(\"</sup>\",\"\") \\\n",
    "                                 .replace(\"<em>\", \"\").replace(\"</em>\",\"\") \\\n",
    "                                 .replace(\"<b>\", \"\").replace(\"</b>\",\"\") \\\n",
    "                                 .replace(\"<I>\", \"\").replace(\"</I>\", \"\") \\\n",
    "                                 .replace(\"<SUB>\", \"\").replace(\"</SUB>\", \"\") \\\n",
    "                                 .replace(\"<scp>\", \"\").replace(\"</scp>\", \"\") \\\n",
    "                                 .replace(\"<font>\", \"\").replace(\"</font>\", \"\") \\\n",
    "                                 .replace(\"<inf>\",\"\").replace(\"</inf>\", \"\") \\\n",
    "                                 .replace(\"<i /> \", \"\") \\\n",
    "                                 .replace(\"<p>\", \"\").replace(\"</p>\",\"\") \\\n",
    "                                 .replace(\"<![CDATA[<B>\", \"\").replace(\"</B>]]>\", \"\") \\\n",
    "                                 .replace(\"<italic>\", \"\").replace(\"</italic>\",\"\")\\\n",
    "                                 .replace(\"<title>\", \"\").replace(\"</title>\", \"\") \\\n",
    "                                 .replace(\"<br>\", \"\").replace(\"</br>\",\"\").replace(\"<br/>\",\"\") \\\n",
    "                                 .replace(\"<B>\", \"\").replace(\"</B>\", \"\") \\\n",
    "                                 .replace(\"<em>\", \"\").replace(\"</em>\", \"\") \\\n",
    "                                 .replace(\"<BR>\", \"\").replace(\"</BR>\", \"\") \\\n",
    "                                 .replace(\"<title>\", \"\").replace(\"</title>\", \"\") \\\n",
    "                                 .replace(\"<strong>\", \"\").replace(\"</strong>\", \"\") \\\n",
    "                                 .replace(\"<formula>\", \"\").replace(\"</formula>\", \"\") \\\n",
    "                                 .replace(\"<roman>\", \"\").replace(\"</roman>\", \"\") \\\n",
    "                                 .replace(\"<SUP>\", \"\").replace(\"</SUP>\", \"\") \\\n",
    "                                 .replace(\"<SSUP>\", \"\").replace(\"</SSUP>\", \"\") \\\n",
    "                                 .replace(\"<sc>\", \"\").replace(\"</sc>\", \"\") \\\n",
    "                                 .replace(\"<subtitle>\", \"\").replace(\"</subtitle>\", \"\") \\\n",
    "                                 .replace(\"<emph/>\", \"\").replace(\"<emph>\", \"\").replace(\"</emph>\", \"\") \\\n",
    "                                 .replace(\"\"\"<p class=\"Body\">\"\"\", \"\") \\\n",
    "                                 .replace(\"<TITLE>\", \"\").replace(\"</TITLE>\", \"\") \\\n",
    "                                 .replace(\"<sub />\", \"\").replace(\"<sub/>\", \"\") \\\n",
    "                                 .replace(\"<mi>\", \"\").replace(\"</mi>\", \"\") \\\n",
    "                                 .replace(\"<bold>\", \"\").replace(\"</bold>\", \"\") \\\n",
    "                                 .replace(\"<mtext>\", \"\").replace(\"</mtext>\", \"\") \\\n",
    "                                 .replace(\"<msub>\", \"\").replace(\"</msub>\", \"\") \\\n",
    "                                 .replace(\"<mrow>\", \"\").replace(\"</mrow>\", \"\") \\\n",
    "                                 .replace(\"</mfenced>\", \"\").replace(\"</math>\", \"\")\n",
    "\n",
    "            if '<mml' in new_title:\n",
    "                all_parts = [x for y in [i.split(\"mml:math>\") for i in new_title.split(\"<mml:math\")] for x in y if x]\n",
    "                final_parts = []\n",
    "                for part in all_parts:\n",
    "                    if re.search(r\"\\>[$%#!^*\\w.,/()+-]*\\<\", part):\n",
    "                        pull_out = re.findall(r\"\\>[$%#!^*\\w.,/()+-]*\\<\", part)\n",
    "                        final_pieces = []\n",
    "                        for piece in pull_out:\n",
    "                            final_pieces.append(piece.replace(\">\", \"\").replace(\"<\", \"\"))\n",
    "                        \n",
    "                        final_parts.append(\" \"+ \"\".join(final_pieces) + \" \")\n",
    "                    else:\n",
    "                        final_parts.append(part)\n",
    "                \n",
    "                new_title = \"\".join(final_parts).strip()\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if '<xref' in new_title:\n",
    "                new_title = re.sub(r\"\\<xref[^/]*\\/xref\\>\", \"\", new_title)\n",
    "\n",
    "            if '<inline-formula' in new_title:\n",
    "                new_title = re.sub(r\"\\<inline-formula[^/]*\\/inline-formula\\>\", \"\", new_title)\n",
    "\n",
    "            if '<title' in new_title:\n",
    "                new_title = re.sub(r\"\\<title[^/]*\\/title\\>\", \"\", new_title)\n",
    "\n",
    "            if '<p class=' in new_title:\n",
    "                new_title = re.sub(r\"\\<p class=[^>]*\\>\", \"\", new_title)\n",
    "            \n",
    "            if '<span class=' in new_title:\n",
    "                new_title = re.sub(r\"\\<span class=[^>]*\\>\", \"\", new_title)\n",
    "\n",
    "            if 'mfenced open' in new_title:\n",
    "                new_title = re.sub(r\"\\<mfenced open=[^>]*\\>\", \"\", new_title)\n",
    "            \n",
    "            if 'math xmlns' in new_title:\n",
    "                new_title = re.sub(r\"\\<math xmlns=[^>]*\\>\", \"\", new_title)\n",
    "\n",
    "        if '<' in new_title:\n",
    "            new_title = new_title.replace(\">i<\", \"\").replace(\">/i<\", \"\") \\\n",
    "                                 .replace(\">b<\", \"\").replace(\">/b<\", \"\") \\\n",
    "                                 .replace(\"<inline-formula>\", \"\").replace(\"</inline-formula>\",\"\")\n",
    "        if new_title.isupper():\n",
    "            new_title = new_title.title()\n",
    "        \n",
    "        return new_title\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def clean_abstract(raw_abstract, inverted=False):\n",
    "    \"\"\"\n",
    "    Function to clean abstract and return it in a format for the model.\n",
    "    \n",
    "    Input:\n",
    "    raw_abstract: string of abstract\n",
    "    inverted: boolean to determine if abstract is inverted index or not\n",
    "    \n",
    "    Output:\n",
    "    final_abstract: string of abstract in format for model\n",
    "    \"\"\"\n",
    "    max_ab_len = 700\n",
    "    if inverted:\n",
    "        if isinstance(raw_abstract, dict) | isinstance(raw_abstract, str):\n",
    "            if isinstance(raw_abstract, dict):\n",
    "                invert_abstract = raw_abstract\n",
    "            else:\n",
    "                invert_abstract = json.loads(raw_abstract)\n",
    "            \n",
    "            if invert_abstract.get('IndexLength'):\n",
    "                ab_len = invert_abstract['IndexLength']\n",
    "\n",
    "                if ab_len > 20:\n",
    "                    abstract = [\" \"]*ab_len\n",
    "                    for key, value in invert_abstract['InvertedIndex'].items():\n",
    "                        for i in value:\n",
    "                            abstract[i] = key\n",
    "                    final_abstract = \" \".join(abstract)[:max_ab_len]\n",
    "                    keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "                    if keep_abs == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        final_abstract = None\n",
    "                else:\n",
    "                    final_abstract = None\n",
    "            else:\n",
    "                if len(invert_abstract) > 20:\n",
    "                    abstract = [\" \"]*1200\n",
    "                    for key, value in invert_abstract.items():\n",
    "                        for i in value:\n",
    "                            try:\n",
    "                                abstract[i] = key\n",
    "                            except:\n",
    "                                pass\n",
    "                    final_abstract = \" \".join(abstract)[:max_ab_len].strip()\n",
    "                    keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "                    if keep_abs == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        final_abstract = None\n",
    "                else:\n",
    "                    final_abstract = None\n",
    "                \n",
    "        else:\n",
    "            final_abstract = None\n",
    "    else:\n",
    "        if raw_abstract:\n",
    "            ab_len = len(raw_abstract)\n",
    "            if ab_len > 30:\n",
    "                final_abstract = raw_abstract[:max_ab_len]\n",
    "                keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "                if keep_abs == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    final_abstract = None\n",
    "            else:\n",
    "                final_abstract = None\n",
    "        else:\n",
    "            final_abstract = None\n",
    "            \n",
    "    return final_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19860a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_abstract_for_df(title, abstract):\n",
    "    max_title_ab_len = 900\n",
    "    if title.isupper():\n",
    "        title = title.title()\n",
    "    if abstract:\n",
    "        title_and_abstract = f\"{title}\\n {abstract}\"\n",
    "    else:\n",
    "        if title:\n",
    "            title_and_abstract = f\"{title}\"\n",
    "        else:\n",
    "            title_and_abstract = \"\"\n",
    "    return title_and_abstract[:max_title_ab_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e30b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_keywords_df(title_abs_emb, title_and_abstract, candidate_topics):\n",
    "    \"\"\"\n",
    "    Function to get keywords based on the topics\n",
    "    \n",
    "    Input:\n",
    "    candidate_topics: topics of paper\n",
    "    \n",
    "    Output:\n",
    "    keywords_data_copy: filtered df of keywords and embeddings\n",
    "    \"\"\"\n",
    "    cand_embs_df = all_keywords_data[all_keywords_data['topic_id'].isin(candidate_topics)]\\\n",
    "        .drop_duplicates(subset=['keywords'])[['keywords','embedding']].copy()\n",
    "    \n",
    "    if title_and_abstract:\n",
    "        # Get scores for each candidate keyword\n",
    "        cand_embs_df['cand_scores'] = cand_embs_df['embedding'].apply(lambda x: np.dot(np.array(title_abs_emb), x))\n",
    "    else:\n",
    "        cand_embs_df['cand_scores'] = -1\n",
    "        \n",
    "    if cand_embs_df[cand_embs_df['cand_scores']>=0].shape[0] > 0:\n",
    "        top_k = cand_embs_df[cand_embs_df['cand_scores']>=0].sort_values('cand_scores', ascending=False).head(5).copy()\n",
    "        top_k['keywords'] = top_k['keywords'].apply(lambda x: x.lower())\n",
    "        top_k = top_k.drop_duplicates(subset=['keywords'])\n",
    "        keywords = top_k['keywords'].tolist()\n",
    "        scores = top_k['cand_scores'].tolist()\n",
    "\n",
    "        final_keywords = []\n",
    "        _ = [final_keywords.append({\"keyword\": keyword, \"score\": score}) for keyword, score in zip(keywords, scores) if score > 0.50]\n",
    "\n",
    "        if final_keywords:\n",
    "            return final_keywords\n",
    "        else:\n",
    "            if scores[0] > 0.40:\n",
    "                return [{\"keyword\": keywords[0], \"score\": scores[0]}]\n",
    "            else:\n",
    "                return []\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45bd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_keywords_df(old_df):\n",
    "    \"\"\"\n",
    "    Function to get keywords that match title/abstract\n",
    "    \n",
    "    Input:\n",
    "    candidate_topics: topic ids for a paper\n",
    "    paper_title: title of a paper\n",
    "    abstract: abstract of a paper\n",
    "    invert_abstract: whether or not the abstract is being input as an inverted index (True/False)\n",
    "    topk: maximum number of keywords to pull for a paper\n",
    "    \n",
    "    Output:\n",
    "    final_keywords\n",
    "    \"\"\"\n",
    "    # Process title and abstract\n",
    "    df = old_df.copy()\n",
    "    df['original_title'] = df['original_title'].apply(clean_title)\n",
    "    df['abstract'] = df['abstract'].apply(clean_title)\n",
    "    \n",
    "    # Get candidate keywords\n",
    "    df['title_abstract'] = df.apply(lambda x: get_title_abstract_for_df(x.original_title, x.abstract), axis=1)\n",
    "    with torch.no_grad():\n",
    "        title_abs_embs = emb_model.encode(df['title_abstract'].tolist())\n",
    "    df['embs'] = title_abs_embs.tolist()\n",
    "    df['keywords'] = df.apply(lambda x: get_candidate_keywords_df(x.embs, x.title_abstract, x.topics), axis=1)\n",
    "    return df['keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c5d974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16611934208, 16935682048)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b452d894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "emb_model = SentenceTransformer('baai/BGE-M3')\n",
    "all_keywords_data = pd.read_parquet('s3://openalex-keywords-matcher/v1/keywords_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c0bb653",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet(\"data_sample_to_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce826402",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "prefix = \"keywords/v2/running_data_through_model/data_to_score/\"\n",
    "response = s3.list_objects_v2(Bucket=\"bucket\", Prefix=prefix)\n",
    "\n",
    "files = []\n",
    "for obj in response['Contents']:\n",
    "    file_key = obj['Key']\n",
    "    if file_key.endswith('parquet'):\n",
    "        files.append(file_key)\n",
    "        \n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e20e3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_score = files[160:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3fe3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0035c296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 169 ms, total: 34 s\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_keys = [get_all_keywords_df(pd.DataFrame(i, columns=list(test_df.columns))) for i in np.array_split(test_df, int(test_df.shape[0]/batch_num))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for full_file_name in keys_to_score:\n",
    "    s3_file = f\"s3://bucket/{full_file_name}\"\n",
    "    file_name = full_file_name.split(\"part-\")[1].split('-')[0]\n",
    "    \n",
    "    print(file_name)\n",
    "    data_to_score = pd.read_parquet(s3_file)\n",
    "    print(data_to_score.shape[0])\n",
    "    final_keys = [get_all_keywords_df(pd.DataFrame(i, columns=list(data_to_score.columns))) for i in \n",
    "              np.array_split(data_to_score, int(data_to_score.shape[0]/batch_num))]\n",
    "    data_to_score['keywords'] = [x for y in final_keys for x in y]\n",
    "    print(len([x for y in final_keys for x in y]))\n",
    "    data_to_score[['paper_id','keywords']].to_parquet(f\"s3://bucket/keywords/v2/running_data_through_model/data_scored_gpu/part_{file_name}.parquet\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddcce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
